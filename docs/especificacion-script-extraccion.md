# Especificaci√≥n T√©cnica: Script de Extracci√≥n de Filtros Jumbo

## Resumen Ejecutivo

Este documento especifica los requerimientos t√©cnicos para desarrollar un script automatizado que extraiga las categor√≠as y filtros del sitio web de Jumbo Argentina, generando una documentaci√≥n completa en formato Markdown.

## Objetivos del Script

- **Automatizaci√≥n completa**: Eliminar el proceso manual de extracci√≥n de filtros
- **Consistencia**: Garantizar que todas las categor√≠as sigan la misma estructura
- **Mantenibilidad**: F√°cil actualizaci√≥n cuando cambien las categor√≠as o filtros
- **Documentaci√≥n**: Generar archivo .md con formato estandarizado

## Arquitectura General del Script

### Flujo Principal
```mermaid
graph TD
    A[Inicio] --> B[Acceder a jumbo.com.ar]
    B --> C[Extraer categor√≠as principales]
    C --> D[Procesar primera categor√≠a]
    D --> E[Extraer filtros de categor√≠a actual]
    E --> F[¬øHay m√°s categor√≠as?]
    F -->|S√≠| G[Pasar a siguiente categor√≠a]
    G --> E
    F -->|No| H[Generar archivo .md]
    H --> I[Fin]
```

## Especificaciones T√©cnicas

### 1. Configuraci√≥n Inicial

#### Dependencias Requeridas
- **Requests**: Para hacer peticiones HTTP
- **BeautifulSoup**: Para parsear HTML
- **Selenium** (opcional): Para contenido din√°mico
- **Markdown**: Para generar la documentaci√≥n

#### Configuraci√≥n del Navegador
```python
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
    'Accept-Language': 'es-AR,es;q=0.9,en;q=0.8',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}
```

### 2. Paso 1: Acceso al Sitio Principal

#### URL Base
- **URL**: `https://www.jumbo.com.ar`
- **M√©todo**: GET
- **Headers**: Configurados para simular navegador real

#### Validaci√≥n de Acceso
- Verificar c√≥digo de respuesta HTTP 200
- Confirmar que el contenido se carg√≥ correctamente
- Manejar posibles bloqueos o restricciones

### 3. Paso 2: Extracci√≥n de Categor√≠as Principales

#### Localizaci√≥n de Categor√≠as
Las categor√≠as se encuentran en la navegaci√≥n principal del sitio. Buscar:
- Elementos `<nav>` o `<ul>` con clase de navegaci√≥n
- Enlaces `<a>` que contengan las URLs de categor√≠as
- Texto de las categor√≠as para nombrado

#### Patr√≥n de URLs
```regex
https://www.jumbo.com.ar/[categoria-nombre]
```

#### Estructura de Datos para Categor√≠as
```python
categories = [
    {
        'name': 'Electro',
        'url': 'https://www.jumbo.com.ar/electro',
        'filters': []  # Se llenar√° despu√©s
    },
    # ... m√°s categor√≠as
]
```

#### Validaci√≥n de Categor√≠as
- Verificar que cada URL sea accesible
- Confirmar que el nombre de categor√≠a sea v√°lido
- Filtrar categor√≠as no relevantes (como "Ofertas", "Novedades", etc.)

### 4. Paso 3: Procesamiento de Categor√≠as Individuales

#### Loop Principal
```python
for category in categories:
    print(f"Procesando categor√≠a: {category['name']}")
    filters = extract_filters_from_category(category['url'])
    category['filters'] = filters
```

### 5. Paso 4: Extracci√≥n de Filtros por Categor√≠a

#### M√©todo de Extracci√≥n
Para cada categor√≠a, acceder a su URL espec√≠fica y extraer:

1. **Filtros Base** (siempre presentes):
   - Categor√≠a
   - Sub-Categor√≠a
   - Tipo de Producto

2. **Filtros Espec√≠ficos**:
   - Buscar en elementos HTML con clases relacionadas a filtros
   - Extraer texto de opciones de filtro
   - Limpiar y validar nombres de filtros

#### T√©cnicas de Extracci√≥n
- **XPath/CSS Selectors**: Para localizar elementos de filtro
- **Regex**: Para extraer nombres de filtros del HTML
- **JSON Parsing**: Si los filtros est√°n en datos estructurados

#### Ejemplo de Selectores
```python
# Posibles selectores para filtros
filter_selectors = [
    '.filter-item',
    '.facet-option',
    '.filter-option',
    '[data-filter]',
    '.search-filter'
]
```

#### Limpieza de Datos
- Remover "Rangos de precio" (como especificado)
- Eliminar duplicados
- Validar nombres de filtros
- Ordenar alfab√©ticamente

### 6. Manejo de Errores y Edge Cases

#### Errores HTTP
- **404**: Categor√≠a no encontrada
- **500**: Error del servidor
- **429**: Rate limiting
- **Timeout**: Conexi√≥n lenta

#### Estrategias de Recuperaci√≥n
- Reintentar con delay exponencial
- Usar proxies alternativos
- Continuar con siguiente categor√≠a si una falla

#### Contenido Din√°mico
- Detectar si la p√°gina usa JavaScript para cargar filtros
- Implementar Selenium como fallback
- Esperar carga completa antes de extraer

### 7. Generaci√≥n del Archivo Markdown

#### Estructura del Archivo
```markdown
## Categorias
1. Electro: https://www.jumbo.com.ar/electro
2. Hogar: https://www.jumbo.com.ar/hogar-y-textil
...

## Filtros por Categor√≠a

### Electro
**Total de filtros: 28**
-- FiltrosCategory
Categor√≠a
Sub-Categor√≠a
-- Tipo de producto
Tipo de Producto
-- Subfiltros
Capacidad de Lavado
Capacidad de Secado
...
```

#### Funci√≥n de Generaci√≥n
```python
def generate_markdown(categories, output_file):
    with open(output_file, 'w', encoding='utf-8') as f:
        # Generar encabezado
        # Generar lista de categor√≠as
        # Generar secciones de filtros
        pass
```

### 8. Logging y Monitoreo

#### Niveles de Logging
- **INFO**: Progreso normal del script
- **WARNING**: Problemas menores (reintentos)
- **ERROR**: Errores cr√≠ticos
- **DEBUG**: Informaci√≥n detallada para troubleshooting

#### M√©tricas a Registrar
- Tiempo total de ejecuci√≥n
- N√∫mero de categor√≠as procesadas
- N√∫mero de filtros extra√≠dos
- Errores encontrados y resueltos

### 9. Configuraci√≥n y Par√°metros

#### Archivo de Configuraci√≥n
```yaml
# config.yaml
site_url: "https://www.jumbo.com.ar"
output_file: "categorias_jumbo.md"
max_retries: 3
delay_between_requests: 1
timeout: 30
user_agent: "Custom User Agent String"
```

#### Par√°metros de L√≠nea de Comando
```bash
python extract_filters.py --config config.yaml --verbose
```

### 10. Consideraciones de Performance

#### Optimizaci√≥n
- **Conexiones persistentes**: Reutilizar conexiones HTTP
- **Multithreading**: Procesar m√∫ltiples categor√≠as en paralelo
- **Caching**: Almacenar resultados intermedios
- **Rate limiting**: Respetar l√≠mites del servidor

#### Recursos del Sistema
- **Memoria**: Mantener bajo consumo para listas grandes
- **CPU**: Optimizar parsing de HTML
- **Disco**: Escribir resultados progresivamente

### 11. Testing y Validaci√≥n

#### Casos de Prueba
- **Categor√≠as v√°lidas**: Verificar extracci√≥n correcta
- **Categor√≠as inv√°lidas**: Manejo de errores
- **Contenido din√°mico**: Selenium fallback
- **Rate limiting**: Comportamiento con l√≠mites

#### Validaci√≥n de Datos
- Verificar estructura del Markdown generado
- Contar filtros y comparar con expectativas
- Validar URLs de categor√≠as
- Revisar consistencia de nombres

### 12. Mantenimiento y Actualizaci√≥n

#### Monitoreo Continuo
- Alertas cuando cambien las categor√≠as
- Detecci√≥n de cambios en filtros
- Actualizaci√≥n autom√°tica del script

#### Versionado
- Control de versiones del script
- Historial de cambios en categor√≠as
- Backup de datos anteriores

### 13. Seguridad y √âtica

#### Consideraciones √âticas
- Respetar robots.txt del sitio
- No sobrecargar el servidor
- Uso leg√≠timo de los datos

#### Medidas de Seguridad
- Rotaci√≥n de User-Agents
- Manejo de CAPTCHAs
- Detecci√≥n de bloqueos

### 14. M√©tricas de √âxito

#### KPIs del Script
- **Tasa de √©xito**: Porcentaje de categor√≠as procesadas correctamente
- **Tiempo de ejecuci√≥n**: Minutos para procesar todas las categor√≠as
- **Precisi√≥n**: Porcentaje de filtros extra√≠dos correctamente
- **Mantenibilidad**: Facilidad para actualizar cuando cambie el sitio

### 15. Plan de Implementaci√≥n

#### Fases de Desarrollo
1. **Fase 1**: Configuraci√≥n b√°sica y acceso al sitio
2. **Fase 2**: Extracci√≥n de categor√≠as principales
3. **Fase 3**: Extracci√≥n de filtros por categor√≠a
4. **Fase 4**: Generaci√≥n del archivo Markdown
5. **Fase 5**: Testing y validaci√≥n
6. **Fase 6**: Optimizaci√≥n y mejoras

#### Deliverables
- Script Python completamente funcional
- Archivo de configuraci√≥n
- Documentaci√≥n de uso
- Tests automatizados
- Archivo Markdown generado

---

## Conclusi√≥n

Esta especificaci√≥n proporciona una gu√≠a completa para desarrollar un script robusto y mantenible que automatice la extracci√≥n de filtros de Jumbo. El enfoque modular permite f√°cil mantenimiento y actualizaci√≥n cuando cambie la estructura del sitio web.

**Pr√≥ximos pasos**: Implementar el script siguiendo esta especificaci√≥n y probar con datos reales.

---

# üó∫Ô∏è Gu√≠a de Etapas de Desarrollo

Esta gu√≠a divide el desarrollo del script en **7 etapas secuenciales**, cada una con objetivos espec√≠ficos, tareas detalladas y criterios de aceptaci√≥n claros.

## üìã Metodolog√≠a de Desarrollo

### Principios Generales
- **Desarrollo incremental**: Cada etapa produce un resultado funcional
- **Testing continuo**: Validar cada componente antes de continuar
- **Documentaci√≥n**: Actualizar documentaci√≥n en cada etapa
- **Control de versiones**: Commits frecuentes con mensajes descriptivos

### Herramientas de Validaci√≥n
- **Tests unitarios**: Para funciones individuales
- **Tests de integraci√≥n**: Para flujos completos
- **Validaci√≥n manual**: Verificaci√≥n visual de resultados
- **Logging**: Registro detallado de operaciones

---

## üöÄ Etapa 1: Configuraci√≥n del Proyecto y Dependencias

### üéØ Objetivo
Establecer la estructura b√°sica del proyecto y configurar todas las dependencias necesarias.

### üìù Tareas Espec√≠ficas

#### 1.1 Crear Estructura de Directorios
```bash
scraper-jumbo/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ scraper.py
‚îÇ   ‚îú‚îÄ‚îÄ extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ generator.py
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_scraper.py
‚îÇ   ‚îú‚îÄ‚îÄ test_extractor.py
‚îÇ   ‚îî‚îÄ‚îÄ test_generator.py
‚îú‚îÄ‚îÄ docs/
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îî‚îÄ‚îÄ logs/
```

#### 1.2 Instalar Dependencias
```bash
pip install requests beautifulsoup4 selenium pyyaml markdown
```

#### 1.3 Configurar Archivo de Configuraci√≥n
```yaml
# config/config.yaml
site_url: "https://www.jumbo.com.ar"
output_file: "categorias_jumbo.md"
max_retries: 3
delay_between_requests: 1
timeout: 30
user_agent: "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
log_level: "INFO"
```

#### 1.4 Implementar Sistema de Logging
```python
# src/config.py
import logging
import yaml

def setup_logging(log_level='INFO'):
    logging.basicConfig(
        level=getattr(logging, log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('logs/scraper.log'),
            logging.StreamHandler()
        ]
    )
```

### ‚úÖ Criterios de Aceptaci√≥n
- [ ] Estructura de directorios creada
- [ ] Todas las dependencias instaladas
- [ ] Archivo de configuraci√≥n funcional
- [ ] Sistema de logging operativo
- [ ] Script b√°sico ejecutable sin errores
- [ ] Tests b√°sicos pasan

### üìä Entregables
- Estructura completa del proyecto
- Archivo `requirements.txt`
- Archivo `config.yaml` funcional
- Sistema de logging configurado

---

## üåê Etapa 2: Acceso B√°sico al Sitio Web

### üéØ Objetivo
Implementar la capacidad de acceder al sitio web de Jumbo y manejar respuestas b√°sicas.

### üìù Tareas Espec√≠ficas

#### 2.1 Implementar Cliente HTTP
```python
# src/scraper.py
import requests
from .config import load_config

class JumboScraper:
    def __init__(self):
        self.config = load_config()
        self.session = requests.Session()
        self.session.headers.update(self._get_headers())

    def _get_headers(self):
        return {
            'User-Agent': self.config['user_agent'],
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'es-AR,es;q=0.9,en;q=0.8',
        }

    def get_page(self, url):
        """Obtener p√°gina con manejo de errores"""
        try:
            response = self.session.get(url, timeout=self.config['timeout'])
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            logger.error(f"Error accediendo a {url}: {e}")
            return None
```

#### 2.2 Implementar Manejo de Errores B√°sico
- Capturar excepciones HTTP
- Implementar reintentos autom√°ticos
- Logging de errores

#### 2.3 Crear Tests de Conectividad
```python
# tests/test_scraper.py
def test_basic_connection():
    scraper = JumboScraper()
    content = scraper.get_page("https://www.jumbo.com.ar")
    assert content is not None
    assert "Jumbo" in content
```

### ‚úÖ Criterios de Aceptaci√≥n
- [ ] Cliente HTTP funcional
- [ ] Acceso exitoso a jumbo.com.ar
- [ ] Manejo b√°sico de errores implementado
- [ ] Tests de conectividad pasan
- [ ] Logging de operaciones HTTP

### üìä Entregables
- Clase `JumboScraper` funcional
- Tests de conectividad
- Manejo b√°sico de errores HTTP

---

## üìÇ Etapa 3: Extracci√≥n de Categor√≠as Principales

### üéØ Objetivo
Extraer la lista completa de categor√≠as principales con sus URLs correspondientes.

### üìù Tareas Espec√≠ficas

#### 3.1 Analizar Estructura HTML
- Inspeccionar navegaci√≥n principal
- Identificar patrones de URLs de categor√≠as
- Localizar elementos de men√∫

#### 3.2 Implementar Extracci√≥n de Categor√≠as
```python
# src/extractor.py
from bs4 import BeautifulSoup

def extract_categories(html_content):
    """Extraer categor√≠as de la p√°gina principal"""
    soup = BeautifulSoup(html_content, 'html.parser')

    categories = []
    # Buscar elementos de navegaci√≥n
    nav_elements = soup.find_all(['a', 'li'], class_=re.compile(r'nav|menu|category'))

    for element in nav_elements:
        href = element.get('href')
        if href and '/categoria' in href:
            name = element.get_text().strip()
            if name and len(name) > 2:
                categories.append({
                    'name': name,
                    'url': f"https://www.jumbo.com.ar{href}",
                    'filters': []
                })

    return categories
```

#### 3.3 Filtrar y Validar Categor√≠as
- Eliminar categor√≠as no relevantes (Ofertas, Novedades, etc.)
- Validar URLs accesibles
- Limpiar nombres de categor√≠as

#### 3.4 Implementar Caching
- Almacenar categor√≠as extra√≠das
- Evitar re-extracci√≥n innecesaria

### ‚úÖ Criterios de Aceptaci√≥n
- [ ] Extracci√≥n exitosa de todas las categor√≠as principales
- [ ] URLs v√°lidas y accesibles
- [ ] Filtrado correcto de categor√≠as irrelevantes
- [ ] Almacenamiento en estructura de datos apropiada
- [ ] Tests de extracci√≥n de categor√≠as

### üìä Entregables
- Funci√≥n `extract_categories()` funcional
- Lista validada de categor√≠as
- Tests de extracci√≥n

---

## üîç Etapa 4: Extracci√≥n de Filtros por Categor√≠a

### üéØ Objetivo
Implementar la l√≥gica para extraer filtros de cada categor√≠a individual.

### üìù Tareas Espec√≠ficas

#### 4.1 Analizar Estructura de Filtros
- Inspeccionar HTML de p√°ginas de categor√≠a
- Identificar selectores CSS para filtros
- Entender estructura de datos de filtros

#### 4.2 Implementar Extracci√≥n de Filtros
```python
# src/extractor.py
def extract_filters(html_content):
    """Extraer filtros de una p√°gina de categor√≠a"""
    soup = BeautifulSoup(html_content, 'html.parser')

    filters = []
    base_filters = ['Categor√≠a', 'Sub-Categor√≠a', 'Tipo de Producto']

    # Buscar elementos de filtro
    filter_elements = soup.find_all(['div', 'li', 'span'], class_=re.compile(r'filter|facet'))

    for element in filter_elements:
        filter_text = element.get_text().strip()
        if (filter_text and
            len(filter_text) > 2 and
            filter_text not in base_filters and
            'precio' not in filter_text.lower()):
            filters.append(filter_text)

    # Limpiar y deduplicar
    unique_filters = list(set(filters))
    unique_filters.sort()

    return base_filters + unique_filters
```

#### 4.3 Implementar Procesamiento por Lotes
- Procesar categor√≠as en lotes peque√±os
- Implementar delays entre requests
- Manejar rate limiting

#### 4.4 Agregar Validaci√≥n de Filtros
- Verificar integridad de datos
- Detectar cambios en estructura
- Logging detallado de extracci√≥n

### ‚úÖ Criterios de Aceptaci√≥n
- [ ] Extracci√≥n exitosa de filtros de al menos 3 categor√≠as
- [ ] Estructura de datos consistente
- [ ] Filtrado correcto de "Rangos de precio"
- [ ] Manejo de errores en extracci√≥n
- [ ] Tests de extracci√≥n de filtros

### üìä Entregables
- Funci√≥n `extract_filters()` funcional
- Procesamiento por lotes implementado
- Tests de extracci√≥n de filtros

---

## üìù Etapa 5: Generaci√≥n del Archivo Markdown

### üéØ Objetivo
Crear el generador que produce el archivo .md final con toda la informaci√≥n extra√≠da.

### üìù Tareas Espec√≠ficas

#### 5.1 Implementar Generador Markdown
```python
# src/generator.py
def generate_markdown(categories, output_file):
    """Generar archivo Markdown con categor√≠as y filtros"""

    with open(output_file, 'w', encoding='utf-8') as f:
        # Encabezado
        f.write("# Categorias\n")
        for i, category in enumerate(categories, 1):
            f.write(f"{i}. {category['name']}: {category['url']}\n")
        f.write("\n")

        # Secci√≥n de filtros
        f.write("## Filtros por Categor√≠a\n\n")

        for category in categories:
            f.write(f"### {category['name']}\n")
            total_filters = len(category['filters'])
            f.write(f"**Total de filtros: {total_filters}**\n")

            # Filtros base
            f.write("-- FiltrosCategory\n")
            f.write("Categor√≠a\n")
            f.write("Sub-Categor√≠a\n")
            f.write("-- Tipo de producto\n")
            f.write("Tipo de Producto\n")
            f.write("-- Subfiltros\n")

            # Filtros espec√≠ficos
            for filter_name in category['filters'][3:]:  # Saltar filtros base
                f.write(f"{filter_name}\n")

            f.write("\n")
```

#### 5.2 Implementar Formateo Avanzado
- Alineaci√≥n consistente
- Encoding UTF-8
- Manejo de caracteres especiales

#### 5.3 Agregar Metadatos
- Timestamp de generaci√≥n
- Versi√≥n del script
- Estad√≠sticas de extracci√≥n

### ‚úÖ Criterios de Aceptaci√≥n
- [ ] Archivo Markdown generado correctamente
- [ ] Formato id√©ntico al manual existente
- [ ] Encoding UTF-8 correcto
- [ ] Conteos de filtros precisos
- [ ] Tests de generaci√≥n

### üìä Entregables
- Funci√≥n `generate_markdown()` funcional
- Archivo .md de ejemplo generado
- Tests de generaci√≥n

---

## üß™ Etapa 6: Testing y Validaci√≥n

### üéØ Objetivo
Implementar suite completa de tests y validar el funcionamiento del script.

### üìù Tareas Espec√≠ficas

#### 6.1 Tests Unitarios
```python
# tests/test_extractor.py
def test_extract_categories():
    # Test con HTML mock
    pass

def test_extract_filters():
    # Test con HTML de categor√≠a mock
    pass
```

#### 6.2 Tests de Integraci√≥n
- Test completo del flujo
- Validaci√≥n de datos end-to-end
- Tests de performance

#### 6.3 Validaci√≥n Manual
- Comparar resultados con extracci√≥n manual
- Verificar precisi√≥n de filtros
- Validar formato del Markdown

#### 6.4 Implementar CI/CD B√°sico
- Tests autom√°ticos en commit
- Linting de c√≥digo
- Validaci√≥n de formato

### ‚úÖ Criterios de Aceptaci√≥n
- [ ] Cobertura de tests > 80%
- [ ] Todos los tests pasan
- [ ] Validaci√≥n manual exitosa
- [ ] Resultados id√©nticos a extracci√≥n manual
- [ ] CI/CD b√°sico implementado

### üìä Entregables
- Suite completa de tests
- Reportes de cobertura
- Validaci√≥n manual documentada

---

## ‚ö° Etapa 7: Optimizaci√≥n y Mejoras

### üéØ Objetivo
Optimizar performance, agregar features avanzadas y preparar para producci√≥n.

### üìù Tareas Espec√≠ficas

#### 7.1 Optimizaciones de Performance
- Implementar multithreading para categor√≠as
- Optimizar parsing HTML
- Implementar caching inteligente

#### 7.2 Features Avanzadas
- Detecci√≥n autom√°tica de cambios
- Modo incremental de actualizaci√≥n
- Dashboard de monitoreo

#### 7.3 Documentaci√≥n Final
- README completo del proyecto
- Gu√≠a de uso detallada
- Documentaci√≥n de API

#### 7.4 Preparaci√≥n para Producci√≥n
- Configuraci√≥n de logging avanzado
- Manejo de credenciales seguras
- Empaquetado del proyecto

### ‚úÖ Criterios de Aceptaci√≥n
- [ ] Performance mejorada significativamente
- [ ] Features avanzadas implementadas
- [ ] Documentaci√≥n completa
- [ ] Listo para despliegue en producci√≥n

### üìä Entregables
- Script optimizado y completo
- Documentaci√≥n final
- Configuraci√≥n de producci√≥n

---

## üìà Seguimiento de Progreso

### Checklist General
- [ ] Etapa 1: Configuraci√≥n del Proyecto
- [ ] Etapa 2: Acceso B√°sico al Sitio Web
- [ ] Etapa 3: Extracci√≥n de Categor√≠as
- [ ] Etapa 4: Extracci√≥n de Filtros
- [ ] Etapa 5: Generaci√≥n Markdown
- [ ] Etapa 6: Testing y Validaci√≥n
- [ ] Etapa 7: Optimizaci√≥n y Producci√≥n

### M√©tricas por Etapa
- **Tiempo estimado**: 2-3 d√≠as por etapa
- **Tests requeridos**: M√≠nimo 5 tests por etapa
- **Documentaci√≥n**: README actualizado por etapa

### Riesgos y Mitigaciones
- **Rate limiting**: Implementar delays y proxies
- **Cambios en sitio**: Tests de regresi√≥n autom√°ticos
- **Dependencias**: Versionado estricto de librer√≠as

---

**Fecha**: Septiembre 2025
**Versi√≥n**: 1.1
**Autor**: GitHub Copilot
**Estado**: Gu√≠a de Desarrollo Completa
